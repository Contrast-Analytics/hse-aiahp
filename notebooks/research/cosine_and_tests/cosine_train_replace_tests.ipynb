{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tests_tests = pd.read_excel(\"data/with_tests/data_with_tests_info_test.xlsx\")[[\"id\", \"error_open_tests\", \"error_closed_tests\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tests(open_, closed_):\n",
    "    if open_ and closed_:\n",
    "        return \"Ошибка в открытых и скрытых тестах. \\n\\n\"\n",
    "    if open_:\n",
    "        return \"Ошибка в открытых тестах. \\n\\n\"\n",
    "    if closed_:\n",
    "        return \"Ошибка в скрытых тестах. \\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_tests[\"text_appending\"] = tests_tests.apply(\n",
    "    lambda x: get_tests(x[\"error_open_tests\"], x[\"error_closed_tests\"]), axis=1\n",
    ")\n",
    "tests_tests = tests_tests.drop([\"error_open_tests\", \"error_closed_tests\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "submission = pd.read_csv(\"submissions/yandex_gpt_raw.csv\")\n",
    "train_solutions = pd.read_csv(\"data/with_pyright/train_solutions_with_pyright.csv\")\n",
    "pyright_solutions = pd.read_csv(\"data/with_pyright/test_solutions_with_pyright.csv\")\n",
    "submission = pd.merge(submission, pyright_solutions[[\"id\", \"message\"]], left_on=\"solution_id\", right_on=\"id\", how=\"left\").drop(\"id\", axis=1)\n",
    "submission = pd.merge(submission, tests_tests, left_on=\"solution_id\", right_on=\"id\", how=\"left\").drop(\"id\", axis=1)\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "# Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "model = AutoModel.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "\n",
    "# Function to compute embeddings for a text\n",
    "def compute_embeddings(text):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "    \n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, mean pooling\n",
    "    return mean_pooling(model_output, encoded_input['attention_mask']).numpy().squeeze()\n",
    "\n",
    "# Apply function to the text column and create a new embeddings column\n",
    "train_solutions['good_embedding'] = train_solutions['author_comment'].apply(compute_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"good_embedding\"] = submission[\"author_comment\"].apply(compute_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution_id</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>author_comment_embedding</th>\n",
       "      <th>message</th>\n",
       "      <th>text_appending</th>\n",
       "      <th>good_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Обратите внимание на то, что в вашем решении н...</td>\n",
       "      <td>-0.6617977023124695 -1.63694167137146 -0.18260...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ошибка в открытых и скрытых тестах. \\n\\n</td>\n",
       "      <td>[1.2556282, 0.016494494, 0.5806775, 0.6323035,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Обратите внимание на закрывающую скобку в стро...</td>\n",
       "      <td>-0.35723087191581726 -0.8950250148773193 -0.01...</td>\n",
       "      <td>\"(\" was not closed</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.8313722, 0.0013448062, 0.25305587, 0.513377...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Обратите внимание на то, что в вашем решении н...</td>\n",
       "      <td>-0.7075666189193726 -1.4730929136276245 -0.093...</td>\n",
       "      <td>\"(\" was not closed</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.9395901, 0.15751688, 0.728238, 0.8257442, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Обратите внимание, что в вашем решении перепут...</td>\n",
       "      <td>-0.7298892736434937 -1.2177058458328247 0.2146...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ошибка в открытых и скрытых тестах. \\n\\n</td>\n",
       "      <td>[1.1250482, -0.16553128, 0.574012, 1.0059338, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Обратите внимание на то, как вычисляется стоим...</td>\n",
       "      <td>-0.5466601252555847 -1.130811095237732 0.69227...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ошибка в открытых и скрытых тестах. \\n\\n</td>\n",
       "      <td>[0.776521, -0.116654016, 0.40440896, 0.4520562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>725</td>\n",
       "      <td>В вашем решении функция success всегда возвращ...</td>\n",
       "      <td>0.007248252630233765 -1.2673029899597168 0.402...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ошибка в открытых и скрытых тестах. \\n\\n</td>\n",
       "      <td>[1.0665845, 0.015698072, 0.27115342, 0.1053895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>726</td>\n",
       "      <td>В вашем решении функция success должна возвращ...</td>\n",
       "      <td>-0.4889887273311615 -1.7024019956588745 0.2202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ошибка в открытых и скрытых тестах. \\n\\n</td>\n",
       "      <td>[0.88942987, 0.0808178, 0.03722991, 0.01825778...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>727</td>\n",
       "      <td>В вашем решении не было обнаружено синтаксичес...</td>\n",
       "      <td>-0.32445967197418213 -0.6892445683479309 -0.14...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ошибка в открытых и скрытых тестах. \\n\\n</td>\n",
       "      <td>[1.2841376, -0.17404707, 0.7482147, 0.71791357...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>728</td>\n",
       "      <td>В вашем решении функция success всегда будет в...</td>\n",
       "      <td>-0.3303411900997162 -1.1162859201431274 0.3479...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ошибка в открытых и скрытых тестах. \\n\\n</td>\n",
       "      <td>[1.0292956, -0.100415654, 0.2885362, 0.2195555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>729</td>\n",
       "      <td>В вашем решении функция success ничего не возв...</td>\n",
       "      <td>-0.47988271713256836 -1.2345348596572876 0.026...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ошибка в открытых и скрытых тестах. \\n\\n</td>\n",
       "      <td>[0.680319, 0.055512287, 0.32206374, -0.260183,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     solution_id                                     author_comment  \\\n",
       "0              0  Обратите внимание на то, что в вашем решении н...   \n",
       "1              1  Обратите внимание на закрывающую скобку в стро...   \n",
       "2              2  Обратите внимание на то, что в вашем решении н...   \n",
       "3              3  Обратите внимание, что в вашем решении перепут...   \n",
       "4              4  Обратите внимание на то, как вычисляется стоим...   \n",
       "..           ...                                                ...   \n",
       "320          725  В вашем решении функция success всегда возвращ...   \n",
       "321          726  В вашем решении функция success должна возвращ...   \n",
       "322          727  В вашем решении не было обнаружено синтаксичес...   \n",
       "323          728  В вашем решении функция success всегда будет в...   \n",
       "324          729  В вашем решении функция success ничего не возв...   \n",
       "\n",
       "                              author_comment_embedding             message  \\\n",
       "0    -0.6617977023124695 -1.63694167137146 -0.18260...                 NaN   \n",
       "1    -0.35723087191581726 -0.8950250148773193 -0.01...  \"(\" was not closed   \n",
       "2    -0.7075666189193726 -1.4730929136276245 -0.093...  \"(\" was not closed   \n",
       "3    -0.7298892736434937 -1.2177058458328247 0.2146...                 NaN   \n",
       "4    -0.5466601252555847 -1.130811095237732 0.69227...                 NaN   \n",
       "..                                                 ...                 ...   \n",
       "320  0.007248252630233765 -1.2673029899597168 0.402...                 NaN   \n",
       "321  -0.4889887273311615 -1.7024019956588745 0.2202...                 NaN   \n",
       "322  -0.32445967197418213 -0.6892445683479309 -0.14...                 NaN   \n",
       "323  -0.3303411900997162 -1.1162859201431274 0.3479...                 NaN   \n",
       "324  -0.47988271713256836 -1.2345348596572876 0.026...                 NaN   \n",
       "\n",
       "                               text_appending  \\\n",
       "0    Ошибка в открытых и скрытых тестах. \\n\\n   \n",
       "1                                        None   \n",
       "2                                        None   \n",
       "3    Ошибка в открытых и скрытых тестах. \\n\\n   \n",
       "4    Ошибка в открытых и скрытых тестах. \\n\\n   \n",
       "..                                        ...   \n",
       "320  Ошибка в открытых и скрытых тестах. \\n\\n   \n",
       "321  Ошибка в открытых и скрытых тестах. \\n\\n   \n",
       "322  Ошибка в открытых и скрытых тестах. \\n\\n   \n",
       "323  Ошибка в открытых и скрытых тестах. \\n\\n   \n",
       "324  Ошибка в открытых и скрытых тестах. \\n\\n   \n",
       "\n",
       "                                        good_embedding  \n",
       "0    [1.2556282, 0.016494494, 0.5806775, 0.6323035,...  \n",
       "1    [0.8313722, 0.0013448062, 0.25305587, 0.513377...  \n",
       "2    [0.9395901, 0.15751688, 0.728238, 0.8257442, 0...  \n",
       "3    [1.1250482, -0.16553128, 0.574012, 1.0059338, ...  \n",
       "4    [0.776521, -0.116654016, 0.40440896, 0.4520562...  \n",
       "..                                                 ...  \n",
       "320  [1.0665845, 0.015698072, 0.27115342, 0.1053895...  \n",
       "321  [0.88942987, 0.0808178, 0.03722991, 0.01825778...  \n",
       "322  [1.2841376, -0.17404707, 0.7482147, 0.71791357...  \n",
       "323  [1.0292956, -0.100415654, 0.2885362, 0.2195555...  \n",
       "324  [0.680319, 0.055512287, 0.32206374, -0.260183,...  \n",
       "\n",
       "[325 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission[\"author_comment\"] = submission.apply(lambda x: x[\"text_appending\"] + x[\"author_comment\"] if x[\"text_appending\"] is not None else x[\"author_comment\"], axis=1)\n",
    "# from app.utils.submit import embedding2string, get_sentence_embedding\n",
    "# submission[\"author_comment_embedding\"] = submission[\"author_comment\"].apply(lambda x: embedding2string(get_sentence_embedding(x)))\n",
    "# submission.drop([\"message\", \"good_embedding\", \"text_appending\"], axis=1).to_csv(\"submissions/added_new_stuff.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to replace texts based on cosine similarity\n",
    "def replace_text_based_on_similarity(train, submission):\n",
    "    train = train.copy()\n",
    "    submission = submission.copy()\n",
    "    # train['author_comment_embedding'] = train['author_comment_embedding'].apply(lambda x: convert_embedding(x))\n",
    "    # submission['author_comment_embedding'] = submission['author_comment_embedding'].apply(lambda x: convert_embedding(x))\n",
    "    # Loop over rows in submission where true_false is True\n",
    "    for idx, row in submission[submission['message'].notna()].iterrows():\n",
    "        # Calculate cosine similarities between the current row's embedding and all true text embeddings\n",
    "        similarities = cosine_similarity([row['good_embedding']], train[train['message'].notna()]['good_embedding'].tolist())\n",
    "        \n",
    "        # Find the index of the most similar embedding in train\n",
    "        most_similar_idx = np.argmax(similarities)\n",
    "\n",
    "        \n",
    "        # Replace the text in submission with the most similar true_text from train\n",
    "        submission.at[idx, 'author_comment'] = train.at[most_similar_idx, \"author_comment\"]\n",
    "\n",
    "    return submission\n",
    "\n",
    "# Example usage\n",
    "df2_updated = replace_text_based_on_similarity(train_solutions, submission)\n",
    "\n",
    "# Now df2 will have the most similar true_text from df1 where true_false is True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...OK\n"
     ]
    }
   ],
   "source": [
    "from app.utils.submit import embedding2string, get_sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_updated[\"author_comment\"] = df2_updated.apply(lambda x: x[\"text_appending\"] + x[\"author_comment\"] if x[\"text_appending\"] is not None else x[\"author_comment\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.submit import embedding2string, get_sentence_embedding\n",
    "df2_updated[\"author_comment_embedding\"] = df2_updated[\"author_comment\"].apply(lambda x: embedding2string(get_sentence_embedding(x)))\n",
    "df2_updated.drop([\"message\", \"good_embedding\", \"text_appending\"], axis=1).to_csv(\"submissions/added_new_stuff_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
