{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install cleantext better_profanity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2396d_FNLAu",
        "outputId": "41ee1613-d02a-43a8-9715-de4219291591"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cleantext\n",
            "  Downloading cleantext-1.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting better_profanity\n",
            "  Downloading better_profanity-0.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from cleantext) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (4.66.5)\n",
            "Downloading cleantext-1.1.4-py3-none-any.whl (4.9 kB)\n",
            "Downloading better_profanity-0.7.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: better_profanity, cleantext\n",
            "Successfully installed better_profanity-0.7.0 cleantext-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from cleantext import clean\n",
        "from better_profanity import profanity\n",
        "\n",
        "\n",
        "file_name = 'obscene_lexicon.txt'\n",
        "with open(file_name, 'r', encoding='utf-8') as file:\n",
        "    bad_words = file.read().split('\\n')\n",
        "\n",
        "def clean_answer(text):\n",
        "    def remove_code_from_text(text):\n",
        "        code_pattern = re.compile(r'\\b(def|class|if|else|elif|for|while|try|except|finally|with|import|from|print|return|break|continue|pass|raise|assert|yield|async|await|lambda|global|nonlocal|del|exec|eval)\\b.*', re.DOTALL)\n",
        "        fenced_code_pattern = re.compile(r'```.*?```', re.DOTALL)\n",
        "        cleaned_text = code_pattern.sub('', text)\n",
        "        cleaned_text = fenced_code_pattern.sub('', cleaned_text)\n",
        "        return cleaned_text\n",
        "\n",
        "    def remove_obscene_lexicon(text):\n",
        "        cleaned_text = clean(text, extra_spaces=True, stemming=False, stopwords=True, lowercase=False, stp_lang='english' )\n",
        "        cleaned_text = profanity.censor(cleaned_text)\n",
        "        for word in bad_words:\n",
        "            bad_words_re = re.compile(r'\\b(' + word + r')\\b', re.IGNORECASE)\n",
        "            cleaned_text = bad_words_re.sub(lambda match: '***', cleaned_text)\n",
        "        return cleaned_text\n",
        "\n",
        "    text = remove_code_from_text(text)\n",
        "    text = remove_obscene_lexicon(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "DQODNHXsMcUK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Можно решить задачу так, проститутка, bitch, хуй:\n",
        "\n",
        "def remove_empty_lines(text):\n",
        "    return \"\\n\".join([line for line in text.splitlines() if line.strip()])\n",
        "\n",
        "def create_request(row):\n",
        "    # Удаляем пустые строки в описании задачи\n",
        "    description = remove_empty_lines(row['description'])\n",
        "    req = f\"Есть задача, описанная так: ${description}$.\"\n",
        "\n",
        "    if row[\"code_problem\"]:\n",
        "        # Удаляем пустые строки в сообщении об ошибке\n",
        "        problem_message = remove_empty_lines(row['problem_message'])\n",
        "        if problem_message:\n",
        "            req += f\" В коде есть ошибка: ${problem_message}$.\"\n",
        "\n",
        "    return req.replace('\\n', '')\n",
        "\"\"\"\n",
        "\n",
        "clean_answer(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "NZPw-MW9MhVf",
        "outputId": "7fe7dffe-7f16-4ec4-f01c-1edf85dfc58c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Можно решить задачу так, ***, ****, ***:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}
